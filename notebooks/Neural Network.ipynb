{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, inputs, targets, eta, epochs, random_state=None):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "        self.progress = []\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def _forward(inputs, weights):\n",
    "        signal = np.dot(inputs, weights)\n",
    "        return np.where(signal > 0, 1, 0)\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Ensure target data is 2D\n",
    "        if self.targets.ndim == 1:\n",
    "            self.targets = self.targets.reshape((-1, 1))\n",
    "            \n",
    "        # Initilize weights to small numbers\n",
    "        weights = np.random.rand(self.inputs.shape[1] + 1, self.targets.shape[1]) * 0.1 - 0.05\n",
    "        bias = -np.ones((self.inputs.shape[0], 1))\n",
    "        inputs_with_bias = np.hstack((self.inputs, bias))\n",
    "        # print(\"DEBUG:: Inputs with bias: {}\".format(inputs_with_bias))\n",
    "        # print(\"DEBUG:: Targets: {}\".format(self.targets))\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            outputs = self._forward(inputs_with_bias, weights)\n",
    "            print(\"DEBUG:: Outputs: {}\".format(outputs.reshape((1, -1))))\n",
    "            weights -= self.eta * np.dot(inputs_with_bias.T, outputs - self.targets)\n",
    "            self.progress.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "or_network = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_network[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p = Perceptron(or_network[:, :2], or_network[:, 2], eta=0.25, epochs=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:: Outputs: [[0 1 0 1]]\n",
      "DEBUG:: Outputs: [[1 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n",
      "DEBUG:: Outputs: [[0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "p.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape((-1, 1))\n",
    "\n",
    "    X = np.hstack((X, -np.ones((X.shape[0], 1))))\n",
    "    beta = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "    \n",
    "    return np.dot(beta, inputs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def linear_regression_2(x, y):\n",
    "#     X = np.matrix(np.vstack([x, -np.ones(len(x))]).T)\n",
    "#     beta = np.linalg.inv(X.T * X) * X.T * np.matrix(y).T\n",
    "#     \n",
    "#     return beta * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 40)\n",
    "y = np.sin(2 * np.pi * X) + np.cos(4 * np.pi * X) + np.random.randn(40) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10ca5f810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD6CAYAAABamQdMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKpDJXZIK9P8BJJUTvC00tNkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c952bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, inputs, targets, num_hidden, beta=1, momentum=0.9,\n",
    "                 activation=\"logistic\", random_state=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        if targets.ndim == 1:\n",
    "            targets = targets.reshape((-1, 1))\n",
    "        self.targets = targets\n",
    "        self.num_input = inputs.shape[1]\n",
    "        self.num_output = targets.shape[1]\n",
    "        self.num_hidden = num_hidden\n",
    "        self.w1, self.w2 = self._initialize_weights()\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.activation = activation\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers\n",
    "        \"\"\"\n",
    "        w1 = (np.random.rand(self.num_input + 1, self.num_hidden) - 0.5) * 2\\\n",
    "            / np.sqrt(self.num_input)  # add 1 for bias node\n",
    "        w2 = (np.random.rand(self.num_hidden + 1, self.num_output) - 0.5) * 2\\\n",
    "            / np.sqrt(self.num_hidden)\n",
    "        return w1, w2\n",
    "\n",
    "    def _add_bias_node(self, inputs):\n",
    "        return np.hstack((inputs, -np.ones((inputs.shape[0], 1))))\n",
    "\n",
    "    def early_stopping(self, valid_inputs, valid_targets, eta, epochs=100):\n",
    "\n",
    "        valid_inputs = self._add_bias_node(valid_inputs)\n",
    "        if valid_targets.ndim == 1:\n",
    "            valid_targets = valid_targets.reshape((-1, 1))\n",
    "\n",
    "        best_valid_error = 100001\n",
    "        valid_error = 100000\n",
    "\n",
    "        cnt = 0\n",
    "        while best_valid_error - valid_error > 1e-3:\n",
    "            cnt += 1\n",
    "            print(\"==> Validation iteration count: {}\".format(cnt))\n",
    "            self.train(eta, epochs)\n",
    "            # best_train_error = self.error_[-1]\n",
    "            best_valid_error = valid_error\n",
    "            valid_outputs = self._forward(valid_inputs, self.w1, self.w2)\n",
    "            valid_error = ((valid_targets - valid_outputs) ** 2).sum() / 2.0\n",
    "            print(\"    Validation error: {}\".format(valid_error))\n",
    "\n",
    "    def train(self, eta, epochs):\n",
    "\n",
    "        self.error_ = []\n",
    "        delta_w1 = np.zeros(self.w1.shape)\n",
    "        delta_w2 = np.zeros(self.w2.shape)\n",
    "\n",
    "        inputs = self._add_bias_node(self.inputs)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            outputs = self._forward(inputs, self.w1, self.w2)\n",
    "            error = ((outputs - self.targets) ** 2).sum() / 2.0\n",
    "            self.error_.append(error)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(\"    Iteration {:3d}: error = {}\".format(i, error))\n",
    "\n",
    "            if self.activation == \"linear\":\n",
    "                output_deltas = (outputs - self.targets) / self.inputs.shape[0]\n",
    "            elif self.activation == \"logistic\":\n",
    "                output_deltas = self.beta\\\n",
    "                    * (outputs - self.targets) * outputs * (1.0 - outputs)\n",
    "            # elif self.activation == \"softmax\":\n",
    "            #     output_deltas =\n",
    "            \n",
    "            hidden_deltas = self.hidden_outputs * self.beta * (1.0 - self.hidden_outputs)\\\n",
    "                * (np.dot(output_deltas, self.w2.T))\n",
    "\n",
    "            delta_w1 = eta * (np.dot(inputs.T, hidden_deltas[:, :-1]))\\\n",
    "                + self.momentum * delta_w1\n",
    "            delta_w2 = eta * (np.dot(self.hidden_outputs.T, output_deltas))\\\n",
    "                + self.momentum * delta_w2\n",
    "            \n",
    "            self.w1 -= delta_w1\n",
    "            self.w2 -= delta_w2\n",
    "\n",
    "    def _forward(self, inputs, w1, w2):\n",
    "        \"\"\"Feed forward\n",
    "        \"\"\"\n",
    "        # inputs = self._add_bias_node(inputs)\n",
    "        z = self.beta * np.dot(inputs, w1)\n",
    "        self.hidden_outputs = np.hstack((self._sigmoid(z), -np.ones((inputs.shape[0], 1))))\n",
    "        outputs = np.dot(self.hidden_outputs, w2)\n",
    "        if self.activation == \"linear\":\n",
    "            outputs = outputs\n",
    "        elif self.activation == \"logistic\":\n",
    "            outputs = self._sigmoid(self.beta * outputs)\n",
    "        # elif self.activation == \"softmax\":\n",
    "        #     # normalizer = \n",
    "        #     return\n",
    "        # else:\n",
    "        #     print(\"WARNING:: Error\")\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return expit(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 40)\n",
    "y = np.sin(2 * np.pi * X) + np.cos(4 * np.pi * X) + np.random.randn(40) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 42)\n",
    "# X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "# X_train = X_train.reshape((-1, 1))\n",
    "# X_valid = X_valid.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = X.reshape((-1, 1))[0::2, :]\n",
    "valid = X.reshape((-1, 1))[3::4, :]\n",
    "y_train = y.reshape((-1, 1))[0::2, :]\n",
    "y_valid = y.reshape((-1, 1))[3::4, :]\n",
    "# print(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn = MLP(train, y_train, 3, activation=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Validation iteration count: 1\n",
      "    Iteration   0: error = 11.1367455831\n",
      "    Iteration 100: error = 6.47886278063\n",
      "    Validation error: 3.56079984533\n",
      "==> Validation iteration count: 2\n",
      "    Iteration   0: error = 6.44770207553\n",
      "    Iteration 100: error = 6.43419561644\n",
      "    Validation error: 3.52292181586\n",
      "==> Validation iteration count: 3\n",
      "    Iteration   0: error = 6.42339370117\n",
      "    Iteration 100: error = 6.41419086565\n",
      "    Validation error: 3.50721443455\n",
      "==> Validation iteration count: 4\n",
      "    Iteration   0: error = 6.40331254795\n",
      "    Iteration 100: error = 6.39199513239\n",
      "    Validation error: 3.49472285627\n",
      "==> Validation iteration count: 5\n",
      "    Iteration   0: error = 6.37729213147\n",
      "    Iteration 100: error = 6.36102881588\n",
      "    Validation error: 3.47801262542\n",
      "==> Validation iteration count: 6\n",
      "    Iteration   0: error = 6.33889958879\n",
      "    Iteration 100: error = 6.31352946122\n",
      "    Validation error: 3.45109922358\n",
      "==> Validation iteration count: 7\n",
      "    Iteration   0: error = 6.27826551333\n",
      "    Iteration 100: error = 6.23774748402\n",
      "    Validation error: 3.40634916107\n",
      "==> Validation iteration count: 8\n",
      "    Iteration   0: error = 6.18270247794\n",
      "    Iteration 100: error = 6.12241029199\n",
      "    Validation error: 3.33642528455\n",
      "==> Validation iteration count: 9\n",
      "    Iteration   0: error = 6.04556955324\n",
      "    Iteration 100: error = 5.96644187424\n",
      "    Validation error: 3.23447245435\n",
      "==> Validation iteration count: 10\n",
      "    Iteration   0: error = 5.86913324441\n",
      "    Iteration 100: error = 5.76830989968\n",
      "    Validation error: 3.07937562044\n",
      "==> Validation iteration count: 11\n",
      "    Iteration   0: error = 5.63679150435\n",
      "    Iteration 100: error = 5.4848392935\n",
      "    Validation error: 2.80320616043\n",
      "==> Validation iteration count: 12\n",
      "    Iteration   0: error = 5.25914296262\n",
      "    Iteration 100: error = 4.97567454347\n",
      "    Validation error: 2.29471301643\n",
      "==> Validation iteration count: 13\n",
      "    Iteration   0: error = 4.55097488223\n",
      "    Iteration 100: error = 4.02012713993\n",
      "    Validation error: 1.49399742017\n",
      "==> Validation iteration count: 14\n",
      "    Iteration   0: error = 3.29995519082\n",
      "    Iteration 100: error = 2.6332035689\n",
      "    Validation error: 0.855012410855\n",
      "==> Validation iteration count: 15\n",
      "    Iteration   0: error = 2.02896764495\n",
      "    Iteration 100: error = 1.6467649165\n",
      "    Validation error: 0.712185745807\n",
      "==> Validation iteration count: 16\n",
      "    Iteration   0: error = 1.38641228689\n",
      "    Iteration 100: error = 1.2517304256\n",
      "    Validation error: 0.784146821246\n"
     ]
    }
   ],
   "source": [
    "nn.early_stopping(valid, y_valid, 0.1, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Classification with The Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encoding of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_encoded = np.zeros((iris.target.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_encoded[np.where(y == 0), 0] = 1\n",
    "y_encoded[np.where(y == 1), 1] = 1\n",
    "y_encoded[np.where(y == 2), 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train, y_train = X[::2, 0:4], y_encoded[::2]\n",
    "valid, y_valid = X[1::4, 0:4], y_encoded[1::4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn2 = MLP(train, y_train, 5, activation=\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Validation iteration count: 1\n",
      "    Iteration   0: error = 26.63155071\n",
      "    Validation error: 6.25246340301\n",
      "==> Validation iteration count: 2\n",
      "    Iteration   0: error = 12.5006592543\n",
      "    Validation error: 6.25007222402\n",
      "==> Validation iteration count: 3\n",
      "    Iteration   0: error = 12.5001465858\n",
      "    Validation error: 6.25007199645\n"
     ]
    }
   ],
   "source": [
    "nn2.early_stopping(valid, y_valid, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
